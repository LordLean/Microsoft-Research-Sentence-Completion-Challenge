{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MSRSCC.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "lE_Df7kjRWdG"
      ],
      "authorship_tag": "ABX9TyOiiWtfeSEAVJn7zjPvDgTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordLean/Microsoft-Research-Sentence-Completion-Challenge/blob/main/MSRSCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3rkNFpbcSGi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1DMObWXht5"
      },
      "source": [
        "import os\n",
        "import random, math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import operator\n",
        "import nltk \n",
        "from nltk import word_tokenize as tokenize\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "from nltk.stem import \tWordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "import tqdm\n",
        "\n",
        "# Download lab2 resources.\n",
        "os.system(\"gdown --id 1H26pdLFh2cDxU-NkflQHzcNCYWUgHCbX\")\n",
        "os.system(\"unzip lab2resources.zip\")\n",
        "\n",
        "# Download scc resources.\n",
        "os.system(\"gdown --id 155TLf2OdXtvfPD8VsWwI2YlHfjS8ph04\")\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM4mZpw2aEU1"
      },
      "source": [
        "# Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "import string\n",
        "\n",
        "stop = set(stopwords.words(\"english\"))\n",
        "punc = string.punctuation\n",
        "\n",
        "# Create stopword + punctuation list.\n",
        "stop_puncs = (set([x for x in punc] + list(stop)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEuqhFH5hRbg"
      },
      "source": [
        "def get_training_testing(training_dir,split=0.5):\n",
        "\n",
        "    filenames=os.listdir(training_dir)\n",
        "    n=len(filenames)\n",
        "    print(\"There are {} files in the training directory: {}\".format(n,training_dir))\n",
        "    # random.seed(53)  #if you want the same random split every time\n",
        "    random.shuffle(filenames)\n",
        "    index=int(n*split)\n",
        "    trainingfiles=filenames[:index]\n",
        "    heldoutfiles=filenames[index:]\n",
        "    return trainingfiles,heldoutfiles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUcl6cc3hS3y"
      },
      "source": [
        "parentdir=\"lab2resources/sentence-completion\"\n",
        "trainingdir=os.path.join(parentdir,\"Holmes_Training_Data\")\n",
        "training,testing=get_training_testing(trainingdir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZXE9SYvcVI2"
      },
      "source": [
        "## N-Gram model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PDt1q87Xf-w"
      },
      "source": [
        "class n_gram_language_model():\n",
        "\n",
        "    \"\"\"\n",
        "    N-gram language model class that stores n-grams and their probabilties learnt from training text\n",
        "    in individiual dictionaries.\n",
        "\n",
        "    Code adapted from the original work of Dr. J Weeds, University of Sussex.   \n",
        "   \n",
        "    Parameters\n",
        "    ----------\n",
        "    trainingdir : str\n",
        "        The training directory where training data can be found.\n",
        "    files : list\n",
        "        List of file names to be trained on.\n",
        "    test_files : list\n",
        "        List of file names for the model to be tested on.\n",
        "    construct_params : dict\n",
        "        Stores the parameters such as known to initialize the language model with.\n",
        "    Attributes\n",
        "    ----------\n",
        "    trainingdir : str\n",
        "        The training directory where training data can be found.\n",
        "    files : list\n",
        "        List of file names to be trained on.\n",
        "    test_files : list\n",
        "        List of file names for the model to be tested on.\n",
        "    construct_params : dict\n",
        "        Stores the parameters such as known to initialize the language model with.\n",
        "    verbose : bool\n",
        "        Whether or not method calls will print progress.\n",
        "    unigram : dict\n",
        "        Dictionary to store unigram probabilities.\n",
        "    bigram : dict\n",
        "        Dictionary to store bigram probabilities.\n",
        "    trigram : dict\n",
        "        Dictionary to store trigram probabilities.\n",
        "    4-gram : dict\n",
        "        Dictionary to store 4-gram probabilities.\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self,trainingdir,files=[], test_files=[], construct_params={}):\n",
        "        self.training_dir=trainingdir\n",
        "        self.files=files\n",
        "        self.test_files = test_files\n",
        "        # Constructor Parameters.\n",
        "        self.construct_params=construct_params\n",
        "        self.verbose = construct_params.get(\"verbose\", False)\n",
        "        self.train()\n",
        "        \n",
        "    def train(self):    \n",
        "        \"\"\"\n",
        "        Method called in model initialization. \n",
        "        Calls \"private\" methods which process files, make unknowns, discount and convert n-gram dictionaries to probabilities. \n",
        "        \"\"\"\n",
        "        self.unigram={}\n",
        "        self.bigram={}\n",
        "        self.trigram={}\n",
        "        self.quad_gram={}\n",
        "         \n",
        "        self._processfiles()\n",
        "        self._make_unknowns(known=self.construct_params.get(\"known\",2))\n",
        "        self._discount()\n",
        "        self._convert_to_probs()\n",
        "\n",
        "        \n",
        "    \n",
        "    def _processline(self,line):\n",
        "        \"\"\"\n",
        "        Method processes lines of txt files and tokenizes sentences contained within.\n",
        "        Information is stored within respective n-gram dictionaries.\n",
        "        \"\"\"\n",
        "        tokens=tokenize(line)\n",
        "        if self.construct_params.get(\"remove_stopwords\",False) == True:\n",
        "          tokens = [token.lower() for token in tokens if token.lower() not in stop_puncs]\n",
        "        if self.construct_params.get(\"lemmatize\", False) == True:\n",
        "          tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
        "        tokens = [\"__START\"] + tokens + [\"__END\"]\n",
        "        previous=\"__END\"\n",
        "        for i, token in enumerate(tokens):\n",
        "            # Unigram\n",
        "            self.unigram[token]=self.unigram.get(token,0)+1\n",
        "            # Bigram\n",
        "            current=self.bigram.get(previous,{})\n",
        "            current[token]=current.get(token,0)+1\n",
        "            self.bigram[previous]=current\n",
        "            previous=token\n",
        "            # Trigram\n",
        "            if i < len(tokens)-2:\n",
        "              # Next words.\n",
        "              next = tokens[i+1] \n",
        "              next_next = tokens[i+2]\n",
        "              # Get dictionaries.\n",
        "              inner = self.trigram.get(token,{})\n",
        "              innermost = inner.get(next,{})\n",
        "              innermost[next_next] = innermost.get(token,0) + 1\n",
        "              # Write frequencies to dictionaries.\n",
        "              inner[next] = innermost\n",
        "              self.trigram[token] = inner\n",
        "            # 4-gram\n",
        "            if i < len(tokens)-3:\n",
        "              # Next words.\n",
        "              next1 = tokens[i+1] \n",
        "              next2 = tokens[i+2]\n",
        "              next3 = tokens[i+3]\n",
        "              # Get dictionaries.\n",
        "              inner1 = self.quad_gram.get(token,{})\n",
        "              inner2 = inner1.get(next1,{})\n",
        "              inner3 = inner2.get(next2,{})\n",
        "              inner3[next3] = inner3.get(token,0) + 1\n",
        "              # Write frequencies to dictionaries.\n",
        "              inner2[next2] = inner3\n",
        "              inner1[next1] = inner2\n",
        "              self.quad_gram[token] = inner1\n",
        "\n",
        "                      \n",
        "            \n",
        "    def _processfiles(self):\n",
        "        \"\"\"\n",
        "        Process text files.\n",
        "        \"\"\"\n",
        "        for afile in tqdm.tqdm(self.files):\n",
        "            # print(\"Processing {}\".format(afile))\n",
        "            try:\n",
        "                with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                    for line in instream:\n",
        "                        line=line.rstrip()\n",
        "                        if len(line)>0:\n",
        "                            self._processline(line)\n",
        "            except UnicodeDecodeError:\n",
        "              if self.verbose:\n",
        "                print(\"UnicodeDecodeError processing {}: ignoring rest of file\".format(afile))\n",
        "              else:\n",
        "                pass\n",
        "      \n",
        "            \n",
        "    def _convert_to_probs(self):\n",
        "        \"\"\"\n",
        "        Convert counts to probabilities for each n-gram dictionary.\n",
        "        \"\"\"\n",
        "        self.unigram={k:v/sum(self.unigram.values()) for (k,v) in self.unigram.items()}\n",
        "        self.bigram={key:{k:v/sum(adict.values()) for (k,v) in adict.items()} for (key,adict) in self.bigram.items()}\n",
        "        self.trigram={k1:{k2:{k3:v/sum(adict2.values()) for k3, v in adict2.items()} for k2, adict2 in adict1.items()} for k1, adict1 in self.trigram.items()}\n",
        "        self.quad_gram={k1:{k2:{k3:{k4:v/sum(adict3.values()) for k4, v in adict3.items()} for k3, adict3 in adict2.items()} for k2, adict2 in adict1.items()} for k1, adict1 in self.quad_gram.items()}\n",
        "        self.kn={k:v/sum(self.kn.values()) for (k,v) in self.kn.items()}\n",
        "    \n",
        "\n",
        "    def nextlikely(self,k=1,current=\"\",method=\"unigram\"):\n",
        "        #use probabilities according to method to generate a likely next sequence\n",
        "        #choose random token from k best\n",
        "        blacklist=[\"__START\",\"__UNK\",\"__DISCOUNT\"]\n",
        "        most_likely = []\n",
        "        if method==\"unigram\":\n",
        "            dist=self.unigram\n",
        "            #sort the tokens by unigram probability\n",
        "            most_likely=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "        elif method == \"bigram\":\n",
        "            dist=self.bigram.get(current,self.bigram.get(\"__UNK\",{}))\n",
        "            most_likely=sorted(list(dist.items()),key=operator.itemgetter(1),reverse=True)\n",
        "        elif method == \"trigram\":\n",
        "            # Split context string for first and second context words.\n",
        "            context = current.split()\n",
        "            c1, c2 = context[0], context[1]\n",
        "            dist = self.trigram[c1][c2]\n",
        "            # Get all words with maximum value.\n",
        "            most_likely = [(k, _) for k, v in dist.items() if v == max(dist.values())]\n",
        "        elif method == \"quad_gram\":\n",
        "            context = current.split(\" \")\n",
        "            c1,c2,c3 = context[0], context[1], context[2]\n",
        "            dist = self.quad_gram[c1][c2][c3]\n",
        "            most_likely = [(k, _) for k, v in dist.items() if v == max(dist.values())]\n",
        "        #filter out any undesirable tokens\n",
        "        filtered=[w for (w,p) in most_likely if w not in blacklist]\n",
        "        #choose one randomly from the top k\n",
        "        res=random.choice(filtered[:k])\n",
        "        return res\n",
        "    \n",
        "    def generate(self,k=3,end=\"__END\",limit=20,method=\"bigram\",methodparams={}):\n",
        "        \"\"\"\n",
        "        Example sentence generator method: Shannon Visualizations.\n",
        "        k selects from the best top(k)s.\n",
        "        \"\"\"\n",
        "        if method==\"\":\n",
        "            method=methodparams.get(\"method\",\"bigram\")\n",
        "        current=\"__START\"\n",
        "        tokens=[]\n",
        "        try: \n",
        "          # Trigram\n",
        "          if method==\"trigram\":\n",
        "            # Set current word to first context.\n",
        "            context_1 = current\n",
        "            # Set random choice of next word to second context.\n",
        "            context_2 = random.choice([key for key, adict in self.trigram[current].items()])\n",
        "            # Check end token hasnt been reached.\n",
        "            while context_2 != end and len(tokens)<limit:\n",
        "              # Pass current contexts to next likely method which re splits them in the tri- 4-gram cases.\n",
        "              current = \" \".join([context_1, context_2])\n",
        "              current = self.nextlikely(k=k, current=current, method=method)\n",
        "              # Append word to the list that will eventually be generated.\n",
        "              tokens.append(current)\n",
        "              # Set the the second context to now be first and the predicted word (current) to be next.\n",
        "              context_1 = context_2\n",
        "              context_2 = current\n",
        "            # After loop return the tokens joined by whitespace.\n",
        "            return \" \".join(tokens[:-1])\n",
        "          # Quad-Gram\n",
        "          elif method == \"quad_gram\":\n",
        "            # Functionality is the same as above with an additional context variable to account for 4 rather than 3 n-grams.\n",
        "            context_1 = current\n",
        "            context_2 = random.choice([key for key, adict in self.quad_gram[context_1].items()])\n",
        "            context_3 = random.choice([key for key, adict in self.quad_gram[context_1][context_2].items()])\n",
        "            while context_3 != end and len(tokens) < limit: \n",
        "              current = \" \".join([context_1, context_2, context_3])\n",
        "              current = self.nextlikely(k=k, current=current, method=method)\n",
        "              tokens.append(current)\n",
        "              context_1 = context_2\n",
        "              context_2 = context_3\n",
        "              context_3 = current\n",
        "            return \" \".join(tokens[:-1])\n",
        "        except:\n",
        "          # If error is thrown rerun method until it generates a valid sentence.\n",
        "          return self.generate(k=k,end=end,limit=limit,method=method,methodparams=methodparams)\n",
        "        # Below calls the unigram and bigram versions of the method.\n",
        "        while current!=end and len(tokens)<limit:\n",
        "            current=self.nextlikely(k=k,current=current,method=method)\n",
        "            tokens.append(current)\n",
        "        return \" \".join(tokens[:-1])\n",
        "    \n",
        "    \n",
        "    def get_prob(self,token,context=\"\",methodparams={}):\n",
        "        if methodparams.get(\"method\",\"unigram\")==\"unigram\":\n",
        "            return self.unigram.get(token,self.unigram.get(\"__UNK\",0))\n",
        "        else:\n",
        "            if methodparams.get(\"smoothing\",\"kneser-ney\")==\"kneser-ney\":\n",
        "                unidist=self.kn\n",
        "            else:\n",
        "                unidist=self.unigram\n",
        "            bigram=self.bigram.get(context[-1],self.bigram.get(\"__UNK\",{}))\n",
        "            big_p=bigram.get(token,bigram.get(\"__UNK\",0))\n",
        "            lmbda=bigram[\"__DISCOUNT\"]\n",
        "            uni_p=unidist.get(token,unidist.get(\"__UNK\",0))\n",
        "            #print(big_p,lmbda,uni_p)\n",
        "            p=big_p+lmbda*uni_p            \n",
        "            return p\n",
        "    \n",
        "    \n",
        "    def compute_prob_line(self,line,methodparams={}):\n",
        "        \"\"\"\n",
        "        Refactored method which calls get_probs() for uni- and bigram cases. Contains functionality for tri- and 4-gram cases within.\n",
        "        Method is not commented as it should be self explanatory:\n",
        "        Lots of if else statements to fit the contexts into a n-gram dictionary. \n",
        "        \n",
        "        #this will add _start to the beginning of a line of text\n",
        "        #compute the probability of the line according to the desired model\n",
        "        #and returns probability together with number of tokens\n",
        "        \"\"\"\n",
        "        tokens=tokenize(line)\n",
        "        if self.construct_params.get(\"remove_stopwords\",False) == True:\n",
        "          tokens = [token.lower() for token in tokens if token.lower() not in stop_puncs]\n",
        "        if self.construct_params.get(\"lemmatize\", False) == True:\n",
        "          tokens = [wordnet_lemmatizer.lemmatize(token) for token in tokens]\n",
        "        tokens = [\"__START\"] + tokens + [\"__END\"]\n",
        "        acc=0\n",
        "        if methodparams.get(\"method\", \"unigram\") in [\"unigram\", \"bigram\"]:\n",
        "          for i,token in enumerate(tokens[1:]):\n",
        "            acc+=math.log(self.get_prob(token,tokens[:i+1],methodparams))\n",
        "          return acc,len(tokens[1:])\n",
        "        # Trigram. \n",
        "        if methodparams.get(\"method\") == \"trigram\":\n",
        "          try:\n",
        "            for i, token in enumerate(tokens[1:]):\n",
        "              if i < len(tokens[1:]) - 3 and len(tokens[1:]) >= 3:\n",
        "                word1, word2, word3 = tokens[i+1], tokens[i+1+1], tokens[i+1+2]\n",
        "                if word1 in self.trigram:\n",
        "                  if word2 in self.trigram[word1]:\n",
        "                    if word3 in self.trigram[word1][word2]:\n",
        "                      acc+=math.log(self.trigram[word1][word2][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[word1][word2][\"__UNK\"])\n",
        "                  else:\n",
        "                    if word3 in self.trigram[word1][\"__UNK\"]:\n",
        "                      acc+=math.log(self.trigram[word1][\"__UNK\"][word3])\n",
        "                    else: \n",
        "                      acc+=math.log(self.trigram[word1][\"__UNK\"][\"__UNK\"])\n",
        "                else:\n",
        "                  if word2 in self.trigram[\"__UNK\"]:\n",
        "                    if word3 in self.trigram[\"__UNK\"][word2]:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][word2][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][word2][\"__UNK\"])\n",
        "                  else:\n",
        "                    if word3 in self.trigram[\"__UNK\"][\"__UNK\"]:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][\"__UNK\"][word3])\n",
        "                    else:\n",
        "                      acc+=math.log(self.trigram[\"__UNK\"][\"__UNK\"][\"__UNK\"])\n",
        "            return acc, len(tokens[1:])\n",
        "          except KeyError:\n",
        "            return acc, len(tokens[1:]) \n",
        "        # Quad_gram - same as above. FYI - if else if statements are used rather than if elif to enhance readability.\n",
        "        if methodparams.get(\"method\") == \"quad_gram\":\n",
        "          try:\n",
        "            for i, token in enumerate(tokens[1:]):\n",
        "              if i < len(tokens[1:]) - 4 and len(tokens[1:]) >= 4:\n",
        "                word1, word2, word3, word4 = tokens[i+1], tokens[i+1+1], tokens[i+1+2], tokens[i+1+3]\n",
        "                if word1 in self.quad_gram:\n",
        "                  if word2 in self.quad_gram[word1]:\n",
        "                    if word3 in self.quad_gram[word1][word2]:\n",
        "                      if word4 in self.quad_gram[word1][word2][word3]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][word3][word4])\n",
        "                      elif \"__UNK\" in self.quad_gram[word1][word2][word3]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][word3][\"__UNK\"])\n",
        "                    else:\n",
        "                      if word4 in self.quad_gram[word1][word2][\"__UNK\"]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][\"__UNK\"][word4])\n",
        "                      elif \"__UNK\" in self.quad_gram[word1][word2][\"__UNK\"]:\n",
        "                        acc+=math.log(self.quad_gram[word1][word2][\"__UNK\"][\"__UNK\"])\n",
        "                  else:\n",
        "                    if \"__UNK\" in self.quad_gram[word1]:\n",
        "                      if word3 in self.quad_gram[word1][\"__UNK\"]:\n",
        "                        if word4 in self.quad_gram[word1][\"__UNK\"][word3]:\n",
        "                          acc+=math.log(self.quad_gram[word1][\"__UNK\"][word3][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[word1][\"__UNK\"][word3]:\n",
        "                          acc+=math.log(self.quad_gram[word1][\"__UNK\"][word3][\"__UNK\"])\n",
        "                      else:\n",
        "                        if \"__UNK\" in self.quad_gram[word1][\"__UNK\"]:\n",
        "                          if word4 in self.quad_gram[word1][\"__UNK\"][\"__UNK\"]:\n",
        "                            acc+=math.log(self.quad_gram[word1][\"__UNK\"][\"__UNK\"][word4])\n",
        "                          elif \"__UNK\" in self.quad_gram[word1][\"__UNK\"][\"__UNK\"]:\n",
        "                            acc+=math.log(self.quad_gram[word1][\"__UNK\"][\"__UNK\"][\"__UNK\"])\n",
        "                else:\n",
        "                  if \"__UNK\" in self.quad_gram:\n",
        "                    if word2 in self.quad_gram[\"__UNK\"]:\n",
        "                      if word3 in self.quad_gram[\"__UNK\"][word2]:\n",
        "                        if word4 in self.quad_gram[\"__UNK\"][word2][word3]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][word3][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[\"__UNK\"][word2][word3]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][word3][\"__UNK\"])\n",
        "                      else:\n",
        "                        if word4 in self.quad_gram[\"__UNK\"][word2][\"__UNK\"]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][\"__UNK\"][word4])\n",
        "                        elif \"__UNK\" in self.quad_gram[\"__UNK\"][word2][\"__UNK\"]:\n",
        "                          acc+=math.log(self.quad_gram[\"__UNK\"][word2][\"__UNK\"][\"__UNK\"])\n",
        "                    else:\n",
        "                      if \"__UNK\" in self.quad_gram[\"__UNK\"]:\n",
        "                        if word3 in self.quad_gram[\"__UNK\"][\"__UNK\"]:\n",
        "                          if word4 in self.quad_gram[\"__UNK\"][\"__UNK\"][word3]:\n",
        "                            acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][word3][word4])\n",
        "                          elif \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"][word3]:\n",
        "                            acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][word3][\"__UNK\"])\n",
        "                        else:\n",
        "                          if \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"]:\n",
        "                            if word4 in self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"]:\n",
        "                              acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"][word4])\n",
        "                            elif \"__UNK\" in self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"]:\n",
        "                              acc+=math.log(self.quad_gram[\"__UNK\"][\"__UNK\"][\"__UNK\"][\"__UNK\"])\n",
        "            return acc, len(tokens[1:])\n",
        "          except KeyError:\n",
        "            return acc, len(tokens[1:]) \n",
        "            \n",
        "    \n",
        "    def compute_probability(self,filenames=[],methodparams={}):\n",
        "        #computes the probability (and length) of a corpus contained in filenames\n",
        "        if filenames==[]:\n",
        "            filenames=self.files\n",
        "        total_p=0\n",
        "        total_N=0\n",
        "        for i,afile in enumerate(filenames):\n",
        "          if self.verbose:\n",
        "            print(\"Processing file {}:{}\".format(i,afile))\n",
        "          try:\n",
        "              with open(os.path.join(self.training_dir,afile)) as instream:\n",
        "                  for line in instream:\n",
        "                      line=line.rstrip()\n",
        "                      if len(line)>0:\n",
        "                          p,N=self.compute_prob_line(line,methodparams=methodparams)\n",
        "                          total_p+=p\n",
        "                          total_N+=N\n",
        "          except UnicodeDecodeError:\n",
        "            if self.verbose:\n",
        "              print(\"UnicodeDecodeError processing file {}: ignoring rest of file\".format(afile))\n",
        "            else:\n",
        "              pass\n",
        "        return total_p,total_N\n",
        "    \n",
        "    def compute_perplexity(self,filenames=[],methodparams={\"method\":\"bigram\",\"smoothing\":\"kneser-ney\"}):\n",
        "        \"\"\"\n",
        "        compute the probability and length of the corpus\n",
        "        calculate perplexity\n",
        "        lower perplexity means that the model better explains the data\n",
        "        \"\"\"\n",
        "        p,N=self.compute_probability(filenames=filenames,methodparams=methodparams)\n",
        "        # print(p,N)\n",
        "        if methodparams.get(\"method\") in [\"trigram\", \"quad_gram\"]:\n",
        "          rem = self.super_counter[methodparams.get(\"method\")] - self.magic_counter[methodparams.get(\"method\")]\n",
        "          pp=math.exp(-p/N) * (self.super_counter[methodparams.get(\"method\")]/rem)\n",
        "          return pp\n",
        "        pp=math.exp(-p/N)\n",
        "        return pp  \n",
        "    \n",
        "\n",
        "    def _make_unknowns(self,known=2):\n",
        "        \"\"\"\n",
        "        Method to distribute probability mass towards the unknown token.\n",
        "        param known (int): dictates cut off point where n-grams less frequent than known are pruned.\n",
        "        \"\"\"\n",
        "        # Unigram -----------------------------------\n",
        "        for (k,v) in list(self.unigram.items()):\n",
        "            if v<known:\n",
        "                del self.unigram[k]\n",
        "                self.unigram[\"__UNK\"]=self.unigram.get(\"__UNK\",0)+v\n",
        "        # Bigram -----------------------------------\n",
        "        for (k,adict) in list(self.bigram.items()):\n",
        "            for (kk,v) in list(adict.items()):\n",
        "                isknown=self.unigram.get(kk,0)\n",
        "                if isknown <= known:\n",
        "                    adict[\"__UNK\"]=adict.get(\"__UNK\",0)+v\n",
        "                    del adict[kk]\n",
        "            isknown=self.unigram.get(k,0)\n",
        "            if isknown <= known:\n",
        "                del self.bigram[k]\n",
        "                current=self.bigram.get(\"__UNK\",{})\n",
        "                current.update(adict)\n",
        "                self.bigram[\"__UNK\"]=current\n",
        "            else:\n",
        "                self.bigram[k]=adict\n",
        "        # Trigram -----------------------------------\n",
        "        for (k1, dict1) in list(self.trigram.items()):\n",
        "          for (k2, dict2) in list(dict1.items()):\n",
        "            for (k3, val) in list(dict2.items()):\n",
        "              isknown=self.unigram.get(k3,0)\n",
        "              if isknown == 0:\n",
        "                dict2[\"__UNK\"] = dict2.get(\"__UNK\",0) + val\n",
        "                del dict2[k3]\n",
        "            isknown=self.unigram.get(k2,0)\n",
        "            if isknown <= known:\n",
        "              del self.trigram[k1][k2]\n",
        "              current=self.trigram[k1].get(\"__UNK\",{})\n",
        "              current.update(dict2)\n",
        "              self.trigram[k1][\"__UNK\"] = current\n",
        "            else:\n",
        "              self.trigram[k1][k2] = dict2\n",
        "          # For first token:\n",
        "          isknown=self.unigram.get(k1,0)\n",
        "          if isknown <= known:\n",
        "            del self.trigram[k1]\n",
        "            current = self.trigram.get(\"__UNK\",{})\n",
        "            current.update(dict1)\n",
        "            self.trigram[\"__UNK\"] = current \n",
        "          else:\n",
        "            self.trigram[k1] = dict1\n",
        "        # Quad Gram -----------------------------------\n",
        "        for (k1, dict1) in list(self.quad_gram.items()):\n",
        "          for (k2, dict2) in list(dict1.items()):\n",
        "            for (k3, dict3) in list(dict2.items()):\n",
        "              for (k4, val) in list(dict3.items()):\n",
        "                # Next\n",
        "                isknown = self.unigram.get(k4,0)\n",
        "                if isknown <= known:\n",
        "                  dict3[\"__UNK\"] = dict3.get(\"__UNK\",0) + val\n",
        "                  del dict3[k4]\n",
        "              # Next\n",
        "              isknown=self.unigram.get(k3,0)\n",
        "              if isknown <= known:\n",
        "                del self.quad_gram[k1][k2][k3]\n",
        "                current = self.quad_gram[k1][k2].get(\"__UNK\", {})\n",
        "                current.update(dict3)\n",
        "                self.quad_gram[k1][k2][\"__UNK\"] = current\n",
        "              else:\n",
        "                self.quad_gram[k1][k2][k3] = dict3\n",
        "            # Next\n",
        "            isknown=self.unigram.get(k2,0)\n",
        "            if isknown <= known:\n",
        "              del self.quad_gram[k1][k2]\n",
        "              current = self.quad_gram[k1].get(\"__UNK\",{})\n",
        "              current.update(dict2)\n",
        "              self.quad_gram[k1][\"__UNK\"] = current\n",
        "            else:\n",
        "              self.quad_gram[k1][k2] = dict2\n",
        "          # Next\n",
        "          isknown=self.unigram.get(k1,0)\n",
        "          if isknown <= known:\n",
        "            del self.quad_gram[k1]\n",
        "            current = self.quad_gram.get(\"__UNK\", {})\n",
        "            current.update(dict1)\n",
        "            self.quad_gram[\"__UNK\"] = current\n",
        "          else:\n",
        "            self.quad_gram[k1] = dict1\n",
        "\n",
        "                \n",
        "    def _discount(self,discount=0.75):\n",
        "        #discount each bigram count by a small fixed amount\n",
        "        self.bigram={k:{kk:value-discount for (kk,value) in adict.items()}for (k,adict) in self.bigram.items()}\n",
        "        \n",
        "        #for each word, store the total amount of the discount so that the total is the same \n",
        "        #i.e., so we are reserving this as probability mass\n",
        "        for k in self.bigram.keys():\n",
        "            lamb=len(self.bigram[k])\n",
        "            self.bigram[k][\"__DISCOUNT\"]=lamb*discount\n",
        "            \n",
        "        #work out kneser-ney unigram probabilities\n",
        "        #count the number of contexts each word has been seen in\n",
        "        self.kn={}\n",
        "        for (k,adict) in self.bigram.items():\n",
        "            for kk in adict.keys():\n",
        "                self.kn[kk]=self.kn.get(kk,0)+1\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrpr8s27mIBW"
      },
      "source": [
        "# Word Embedding methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwD16uqsoDwi"
      },
      "source": [
        "### Pre-trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmlsYpylcIKB"
      },
      "source": [
        "# Note - uses gensim version 4.0.1\n",
        "import gensim.downloader as api\n",
        "\n",
        "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')\n",
        "word2vec_model300 = api.load('word2vec-google-news-300')\n",
        "glove_model300 = api.load('glove-wiki-gigaword-300')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJkps-Nomme3"
      },
      "source": [
        "def processfiles(max_files=10):\n",
        "    \"\"\"\n",
        "    Code adapted from n_gram_language_model class definition.\n",
        "    Returns lists of preprocessed and not tokenized sentences.\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    sentences_preprocessed = []\n",
        "    for afile in tqdm.tqdm(training):\n",
        "        # print(\"Processing {}\".format(afile))\n",
        "        try:\n",
        "            with open(os.path.join(trainingdir,afile)) as instream:\n",
        "                for line in instream:\n",
        "                    line=line.rstrip()\n",
        "                    if len(line)>0:\n",
        "                        tokens = [token for token in tokenize(line) if token not in stop_puncs]\n",
        "                        sentences_preprocessed.append(tokens)\n",
        "                        tokens = [token for token in tokenize(line)]\n",
        "                        sentences.append(tokens)\n",
        "        except UnicodeDecodeError:\n",
        "            print(\"\\nUnicodeDecodeError processing {}: ignoring rest of file\".format(afile))\n",
        "    return sentences, sentences_preprocessed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOa3N_TOm7fX"
      },
      "source": [
        "# Code to create gensim models to be trained on gutenberg text.\n",
        "from gensim.models import Word2Vec, FastText\n",
        "\n",
        "def create_word2vec_gensim(sentences, window=5, vector_size=100, skip_gram=1, negative=5, alpha=0.05, epochs=15, seed=1):\n",
        "  return Word2Vec(sentences,\n",
        "                  window = window,\n",
        "                  vector_size = vector_size,\n",
        "                  sg = skip_gram,\n",
        "                  negative = negative,\n",
        "                  alpha = alpha,\n",
        "                  epochs = epochs,\n",
        "                  seed = seed)\n",
        "    \n",
        "\n",
        "def create_fasttext_gensim(sentences, window=5, vector_size=100, skip_gram=1, negative=5, alpha=0.05, epochs=15, min_n=3, max_n=6, seed=1):\n",
        "  return FastText(sentences,\n",
        "                  window = window,\n",
        "                  vector_size = vector_size,\n",
        "                  sg = skip_gram,\n",
        "                  negative = negative,\n",
        "                  alpha = alpha,\n",
        "                  epochs = epochs,\n",
        "                  min_n = min_n,\n",
        "                  max_n = max_n,\n",
        "                  seed = seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPqHwz88cFUn"
      },
      "source": [
        "# Ensemble\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGiBW1bcoGmL"
      },
      "source": [
        "### N-gram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UZPU0r-oJWa",
        "outputId": "14d5b423-688a-4ac7-9ebd-3beb40e14005"
      },
      "source": [
        "construct_params = {\n",
        "    \"known\" : 5,\n",
        "    \"verbose\" : False,\n",
        "    \"remove_stopwords\" : True\n",
        "}\n",
        "\n",
        "# Initialize n-gram language model.\n",
        "lm=n_gram_language_model(trainingdir=trainingdir,files=training, test_files=[], construct_params=construct_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 261/261 [07:05<00:00,  1.63s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPv-LPa4oTza"
      },
      "source": [
        "additional_args = {\"n_gram_model\" : lm, \"pre_emb_model\" : fasttext_model300, \"ensemble\" : True}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZnklD5JxNsp"
      },
      "source": [
        "# Questions and Answers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfQqXooNNlvP"
      },
      "source": [
        "import pandas as pd, csv\n",
        "questions=os.path.join(parentdir,\"testing_data.csv\")\n",
        "answers=os.path.join(parentdir,\"test_answer.csv\")\n",
        "\n",
        "with open(questions) as instream:\n",
        "    csvreader=csv.reader(instream)\n",
        "    lines=list(csvreader)\n",
        "qs_df=pd.DataFrame(lines[1:],columns=lines[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7P-4UZtNlvR"
      },
      "source": [
        "##  Building and evaluating an SCC system\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1Mos5VvNlvT"
      },
      "source": [
        "class question:\n",
        "\n",
        "    \"\"\"\n",
        "    Question class which stores information about a singular MSR SCC question.\n",
        "\n",
        "    Code adapted from the original work of  Dr. J Weeds, University of Sussex.   \n",
        "   \n",
        "    Parameters\n",
        "    ----------\n",
        "    aline : str\n",
        "        The training directory where training data can be found.\n",
        "    files : list\n",
        "        List of file names to be trained on.\n",
        "    test_files : list\n",
        "        List of file names for the model to be tested on.\n",
        "    construct_params : dict\n",
        "        Stores the parameters such as known to initialize the language model with.\n",
        "    Attributes\n",
        "    ----------\n",
        "    trainingdir : str\n",
        "        The training directory where training data can be found.\n",
        "    files : list\n",
        "        List of file names to be trained on.\n",
        "    test_files : list\n",
        "        List of file names for the model to be tested on.\n",
        "    construct_params : dict\n",
        "        Stores the parameters such as known to initialize the language model with.\n",
        "    verbose : bool\n",
        "        Whether or not method calls will print progress.\n",
        "    unigram : dict\n",
        "        Dictionary to store unigram probabilities.\n",
        "    bigram : dict\n",
        "        Dictionary to store bigram probabilities.\n",
        "    trigram : dict\n",
        "        Dictionary to store trigram probabilities.\n",
        "    4-gram : dict\n",
        "        Dict\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    def __init__(self,aline,stop=True):\n",
        "        self.fields=aline\n",
        "        self.num2letter = {\n",
        "            0:\"a\",\n",
        "            1:\"b\",\n",
        "            2:\"c\",\n",
        "            3:\"d\",\n",
        "            4:\"e\"\n",
        "            }\n",
        "        self.stop = stop\n",
        "        if self.stop:\n",
        "          self.tokenized = [token.lower() for token in tokenize(self.fields[1]) if token.lower() not in stop_puncs]\n",
        "          # self.tokenized = [wordnet_lemmatizer.lemmatize(token) for token in self.tokenized]\n",
        "        else:\n",
        "          self.tokenized = tokenize(self.fields[1])\n",
        "        self.options = self.fields[2:7]\n",
        "        self.backoff_factor = 0.4\n",
        "          \n",
        "\n",
        "    def get_field(self,field):\n",
        "        return self.fields[question.colnames[field]]\n",
        "    \n",
        "\n",
        "    def add_answer(self,fields):\n",
        "        self.answer=fields[1]\n",
        "   \n",
        "\n",
        "    def get_context(self,window,target=\"_____\",method=\"left\"):\n",
        "      \"\"\"\n",
        "      Method to return the context of a target word in question sentence. \n",
        "      If not sufficient context the method returns context with unknown token padding.\n",
        "      \"\"\"\n",
        "      for i, token in enumerate(self.tokenized):\n",
        "        if token == target:\n",
        "            if method==\"left\":\n",
        "              try:\n",
        "                return self.tokenized[i-window:i]\n",
        "              except:\n",
        "                return [\"__UNK\"] * window\n",
        "            elif method==\"right\": \n",
        "              return self.tokenized[i+1:i+1+window]\n",
        "\n",
        "\n",
        "    def chooseA(self):\n",
        "        return(\"a\")\n",
        "\n",
        "\n",
        "    def random(self):\n",
        "      \"\"\"\n",
        "      Retrun random choice of letter.\n",
        "      \"\"\"\n",
        "      return random.choice(self.num2letter)\n",
        "\n",
        "\n",
        "    def unigram(self):\n",
        "      \"\"\"\n",
        "      Return position of word with greatest unigram probability. 0 otherwise.\n",
        "      \"\"\"\n",
        "      option_probs = [lm.unigram[word] if word in lm.unigram else 0 for word in self.options]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def bigram(self, context_dir=\"left\"): # Backoff\n",
        "      \"\"\"\n",
        "      Return position of word-pair with greatest bigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = self.get_context(1, method=context_dir) # [0] to delist context.\n",
        "      context = [\"__UNK\"] + context\n",
        "      if context_dir == \"left\":\n",
        "        for word in self.options:\n",
        "          # Bigram.\n",
        "          if context[-1] in lm.bigram and word in lm.bigram[context[-1]]:\n",
        "            option_probs.append(lm.bigram[context[-1]][word])\n",
        "          # Back off to unigram\n",
        "          elif word in lm.unigram:\n",
        "            option_probs.append(self.backoff_factor * lm.unigram[word])\n",
        "          else:\n",
        "            option_probs.append(0)\n",
        "      elif context_dir == \"right\":\n",
        "        option_probs = [lm.bigram[word][context] if word in lm.bigram and context in lm.bigram[word] else 0 for word in self.options]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def trigram(self, context_dir=\"left\"): # Backoff\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = self.get_context(2, method=context_dir)\n",
        "      context = [\"__UNK\"] * 2 + context \n",
        "      if context_dir == \"left\":\n",
        "        for word in self.options:\n",
        "          if context[-2] in lm.trigram and context[-1] in lm.trigram[context[-2]] and word in lm.trigram[context[-2]][context[-1]]:\n",
        "            option_probs.append(lm.trigram[context[-2]][context[-1]][word])\n",
        "          # Back off to bigram.\n",
        "          elif context[-1] in lm.bigram and word in lm.bigram[context[-1]]:\n",
        "            option_probs.append(self.backoff_factor * lm.bigram[context[-1]][word])\n",
        "          # Back off to unigram.\n",
        "          elif word in lm.unigram:\n",
        "            option_probs.append(self.backoff_factor * self.backoff_factor * lm.unigram[word])\n",
        "          # Else 0.\n",
        "          else:\n",
        "            option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def quad_gram(self, context_dir=\"left\"): # Backoff\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = self.get_context(3, method=context_dir)\n",
        "      context = [\"__UNK\"] * 3 + context\n",
        "      for word in self.options:\n",
        "        if context[-3] in lm.quad_gram and context[-2] in lm.quad_gram[context[-3]] and context[-1] in lm.quad_gram[context[-3]][context[-2]] and word in lm.quad_gram[context[-3]][context[-2]][context[-1]]:\n",
        "          option_probs.append(lm.quad_gram[context[-3]][context[-2]][context[-1]][word])\n",
        "        # Back off to trigram.\n",
        "        elif context[-2] in lm.trigram and context[-1] in lm.trigram[context[-2]] and word in lm.trigram[context[-2]][context[-1]]:\n",
        "          option_probs.append(self.backoff_factor * lm.trigram[context[-2]][context[-1]][word])\n",
        "        # Back off to bigram.\n",
        "        elif context[-1] in lm.bigram and word in lm.bigram[context[-1]]:\n",
        "          option_probs.append((self.backoff_factor**2) *lm.bigram[context[-1]][word])\n",
        "        # Back off to unigram.\n",
        "        elif word in lm.unigram:\n",
        "          option_probs.append((self.backoff_factor**3) * lm.unigram[word])\n",
        "        # Else 0.\n",
        "        else:\n",
        "          option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "   \n",
        "\n",
        "    def simple_4_gram(self, additional_args={}):\n",
        "      lm = additional_args.get(\"n_gram_model\")\n",
        "      option_probs = []\n",
        "      left_context = self.get_context(3, method=\"left\")\n",
        "      left_context = [\"__UNK\"] * 3 + left_context\n",
        "      con1 = left_context[-3]\n",
        "      con2 = left_context[-2]\n",
        "      con3 = left_context[-1]\n",
        "      right_context = self.get_context(3, method=\"right\")\n",
        "      right_context = right_context + [\"__UNK\"] * 3\n",
        "      r_con1 = right_context[0]\n",
        "      r_con2 = right_context[1]\n",
        "      r_con3 = right_context[2]\n",
        "      for word in self.options:\n",
        "        try:\n",
        "          score = 0\n",
        "          # Bigram\n",
        "          if word in lm.bigram.get(con3,{}):\n",
        "            score += 1\n",
        "          if r_con1 in lm.bigram.get(word,{}):\n",
        "            score += 1\n",
        "          # Trigram\n",
        "          if word in lm.trigram.get(con3,{}).get(con2,{}):\n",
        "            score += 2\n",
        "          if r_con1 in lm.trigram.get(con3,{}).get(word,{}):\n",
        "            score += 2\n",
        "          if r_con2 in lm.trigram.get(word,{}).get(r_con1,{}):\n",
        "            score += 2\n",
        "          # Quad_gram\n",
        "          if word in lm.quad_gram.get(con1,{}).get(con2,{}).get(con3,{}):\n",
        "            score += 3\n",
        "          if r_con1 in lm.quad_gram.get(con2,{}).get(con3,{}).get(word,{}):\n",
        "            score += 3\n",
        "          if r_con2 in lm.quad_gram.get(con3,{}).get(word,{}).get(r_con1,{}):\n",
        "            score += 3\n",
        "          if r_con3 in lm.quad_gram.get(word,{}).get(r_con1,{}).get(r_con2,{}):\n",
        "            score += 3\n",
        "          option_probs.append(score)\n",
        "        except TypeError:\n",
        "          print([con1,con2,con3,word,r_con1,r_con2,r_con3])\n",
        "          option_probs.append(0)\n",
        "      # -------------\n",
        "      # Ensemble\n",
        "      if additional_args.get(\"ensemble\", False):\n",
        "        return option_probs\n",
        "      # -------------\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def embedding_similarity(self, method=\"cos\", additional_args={}):\n",
        "      \"\"\"\n",
        "      For use with pretrained or even custom embeddings.\n",
        "      \"\"\"\n",
        "      model = additional_args.get(\"pre_emb_model\")\n",
        "      option_probs = []\n",
        "      # Remove target string.\n",
        "      sentence = self.tokenized #.remove(\"_____\")\n",
        "      # Iterate through candidate choices.\n",
        "      for word in self.options:\n",
        "        try:\n",
        "          # If no embedding for that word exists.\n",
        "          if word not in model.wv:\n",
        "            option_probs.append(0)\n",
        "            # Continue to next candidate word.\n",
        "            continue\n",
        "          # Get vectorized form of word.\n",
        "          word_vector = model.wv.get_vector(word)\n",
        "          # Get vectorized form of sentence tokens.\n",
        "          sentence_vectors = [model.wv.get_vector(sent_token) for sent_token in sentence if sent_token in model.wv and sent_token != \"_____\"]\n",
        "          # For euclidean distances.\n",
        "          if method == \"euc\":\n",
        "            sim_score = [np.linalg.norm(model.wv.get_vector(word) - model.wv.get_vector(sent_token)) for sent_token in sentence if sent_token in model.wv and sent_token != \"_____\"]\n",
        "          # For cosine distances.\n",
        "          else:\n",
        "            sim_score = model.wv.cosine_similarities(word_vector, sentence_vectors)\n",
        "          # Append average \"method\" similarity.\n",
        "          option_probs.append(sum(sim_score)/len(sim_score))\n",
        "        except (TypeError, np.AxisError, ZeroDivisionError) as e:\n",
        "          print(sentence)\n",
        "          option_probs.append(0)\n",
        "      # ----------------\n",
        "      # Ensemble - cosine:\n",
        "      if additional_args.get(\"ensemble\", False):\n",
        "        return option_probs\n",
        "      # ----------------\n",
        "      if method == \"cos\":\n",
        "        index = option_probs.index(max(option_probs))\n",
        "      else:\n",
        "        index = option_probs.index(min(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def ensemble(self, additional_args={}):\n",
        "      \"\"\"\n",
        "      Ensemble method which aggregates scores of both tested models and normalizes + sums them.\n",
        "      \"\"\"\n",
        "      n_gram_model = additional_args.get(\"n_gram_model\")\n",
        "      n_gram = self.simple_4_gram(additional_args=additional_args)\n",
        "      norm_n_gram = [float(i)/sum(n_gram) if sum(n_gram) !=0 else 0 for i in n_gram]\n",
        "\n",
        "      pre_emb_model = additional_args.get(\"pre_emb_model\")\n",
        "      pre_emb = self.embedding_similarity(additional_args=additional_args)\n",
        "      norm_pre_emb = [float(i)/sum(pre_emb) if sum(pre_emb) !=0 else 0 for i in pre_emb]\n",
        "\n",
        "      option_probs = [sum(val) for val in zip(norm_n_gram, norm_pre_emb)]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "  # ################################################### comment below to use stupid backoff.\n",
        "    def bigram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-pair with greatest bigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      try:\n",
        "        context = self.get_context(1, method=context_dir)[0] # [0] to delist context.\n",
        "      except:\n",
        "        context = [\"__START\"][0] \n",
        "      if context_dir == \"left\":\n",
        "        option_probs = [lm.bigram[context][word] if context in lm.bigram and word in lm.bigram[context] else 0 for word in self.options]\n",
        "      elif context_dir == \"right\":\n",
        "        option_probs = [lm.bigram[word][context] if word in lm.bigram and context in lm.bigram[word] else 0 for word in self.options]\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def trigram(self, context_dir=\"left\"): \n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      try:\n",
        "        context = [\"__UNK\"] * 2 + self.get_context(2, method=context_dir)\n",
        "      except:\n",
        "        context = [\"__UNK\"] * 2 + context\n",
        "      if context_dir == \"left\":\n",
        "        for word in self.options:\n",
        "          if context[-2] in lm.trigram and context[-1] in lm.trigram[context[-2]] and word in lm.trigram[context[-2]][context[-1]]:\n",
        "            option_probs.append(lm.trigram[context[-2]][context[-1]][word])\n",
        "          elif context[-2] in lm.trigram and context[-1] in lm.trigram[context[-2]] and \"__UNK\" in lm.trigram[context[-2]][context[-1]]:\n",
        "            option_probs.append(lm.trigram[context[-2]][context[-1]][\"__UNK\"])\n",
        "          # Else 0.\n",
        "          else:\n",
        "            option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "\n",
        "\n",
        "    def quad_gram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = [\"__UNK\"] * 3 + self.get_context(3, method=context_dir)\n",
        "      con_len = len(context)\n",
        "      for word in self.options:\n",
        "        if context[-3] in lm.quad_gram and context[-2] in lm.quad_gram[context[-3]] and context[-1] in lm.quad_gram[context[-3]][context[-2]] and word in lm.quad_gram[context[-3]][context[-2]][context[-1]]:\n",
        "          option_probs.append(lm.quad_gram[context[-3]][context[-2]][context[-1]][word])\n",
        "        elif context[-3] in lm.quad_gram and context[-2] in lm.quad_gram[context[-3]] and context[-1] in lm.quad_gram[context[-3]][context[-2]] and \"__UNK\" in lm.quad_gram[context[-3]][context[-2]][context[-1]]:\n",
        "          option_probs.append(lm.quad_gram[context[-3]][context[-2]][context[-1]][\"__UNK\"])\n",
        "        else:\n",
        "          option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "    \n",
        "    def quad_gram(self, context_dir=\"left\"):\n",
        "      \"\"\"\n",
        "      Return position of word-group with greatest trigram probability. 0 otherwise. \n",
        "      \"\"\"\n",
        "      option_probs = []\n",
        "      context = [\"__UNK\"] * 3 + self.get_context(3, method=context_dir)\n",
        "      con1, con2, con3 = context[-3], context[-2], context[-1]\n",
        "      try:\n",
        "        if con1 not in lm.quad_gram:\n",
        "          con1 = \"__UNK\"\n",
        "        if con2 not in lm.quad_gram[con1]:\n",
        "          con2 = \"__UNK\"\n",
        "        if con3 not in lm.quad_gram[con1][con2]:\n",
        "          con3 = \"__UNK\"\n",
        "        for word in self.options:\n",
        "          if con1 in lm.quad_gram and con2 in lm.quad_gram[con1] and con3 in lm.quad_gram[con1][con2] and word in lm.quad_gram[con1][con2][con3]:\n",
        "            option_probs.append(lm.quad_gram[con1][con2][con3][word])\n",
        "          elif con1 in lm.quad_gram and con2 in lm.quad_gram[con1] and con3 in lm.quad_gram[con1][con2] and \"__UNK\" in lm.quad_gram[con1][con2][con3]:\n",
        "            option_probs.append(lm.quad_gram[con1][con2][con3][\"__UNK\"])\n",
        "          else:\n",
        "            option_probs.append(0)\n",
        "      except KeyError:\n",
        "        option_probs.append(0)\n",
        "      index = option_probs.index(max(option_probs))\n",
        "      return self.num2letter[index]\n",
        "  # ################################################### \n",
        "    \n",
        "    \n",
        "    def predict(self, method=\"chooseA\", additional_args=None):\n",
        "        if method==\"chooseA\":\n",
        "          return self.chooseA()\n",
        "        elif method==\"random\":\n",
        "          return self.random()\n",
        "        elif method==\"unigram\":\n",
        "          return self.unigram()\n",
        "        elif method==\"bigram\":\n",
        "          return self.bigram()\n",
        "        elif method==\"trigram\":\n",
        "          return self.trigram()\n",
        "        elif method==\"quad_gram\":\n",
        "          return self.quad_gram()\n",
        "        elif method==\"simple_4_gram\":\n",
        "          return self.simple_4_gram(additional_args=additional_args)\n",
        "        elif method==\"embedding_similarity\":\n",
        "          return self.embedding_similarity(additional_args=additional_args)\n",
        "        elif method==\"ensemble\":\n",
        "          return self.ensemble(additional_args=additional_args)\n",
        "        elif method == \"cos\":\n",
        "          return self.embedding_similarity(additional_args=additional_args)\n",
        "        elif method == \"euc\":\n",
        "          return self.embedding_similarity(additional_args=args,method=\"euc\")\n",
        "\n",
        "\n",
        "    def predict_and_score(self, method=\"chooseA\", additional_args=None):\n",
        "        #compare prediction according to method with the correct answer\n",
        "        #return 1 or 0 accordingly\n",
        "        # Method also records which questions were answered correctly by index.\n",
        "        prediction=self.predict(method=method, additional_args=additional_args)\n",
        "        if prediction == self.answer:\n",
        "            correct_answers.get(method).append(1)\n",
        "            return 1\n",
        "        else:\n",
        "            correct_answers.get(method).append(0)\n",
        "            return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DR5JVkwtuYdF"
      },
      "source": [
        "class scc_reader:\n",
        "    \n",
        "\n",
        "    def __init__(self,qs=questions,ans=answers,stop=False):\n",
        "        self.qs=qs\n",
        "        self.ans=ans\n",
        "        self.stop = stop\n",
        "        self.read_files()\n",
        "\n",
        "\n",
        "    def read_files(self):\n",
        "        \n",
        "        #read in the question file\n",
        "        with open(self.qs) as instream:\n",
        "            csvreader=csv.reader(instream)\n",
        "            qlines=list(csvreader)\n",
        "        \n",
        "        #store the column names as a reverse index so they can be used to reference parts of the question\n",
        "        question.colnames={item:i for i,item in enumerate(qlines[0])}\n",
        "        \n",
        "        #create a question instance for each line of the file (other than heading line)\n",
        "        self.questions=[question(qline, self.stop) for qline in qlines[1:]]\n",
        "        \n",
        "        #read in the answer file\n",
        "        with open(self.ans) as instream:\n",
        "            csvreader=csv.reader(instream)\n",
        "            alines=list(csvreader)\n",
        "            \n",
        "        #add answers to questions so predictions can be checked    \n",
        "        for q,aline in zip(self.questions,alines[1:]):\n",
        "            q.add_answer(aline)\n",
        "\n",
        "\n",
        "    def get_field(self,field):\n",
        "        return [q.get_field(field) for q in self.questions] \n",
        "    \n",
        "\n",
        "    def predict(self,method=\"chooseA\"):\n",
        "        return [q.predict(method=method) for q in self.questions]\n",
        "    \n",
        "    def predict_and_score(self,method=\"chooseA\", additional_args=None):\n",
        "        scores=[q.predict_and_score(method=method, additional_args=additional_args) for q in self.questions]\n",
        "        return sum(scores)/len(scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEfpdtRQPbfD"
      },
      "source": [
        "## Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNCmAD2WyCqx"
      },
      "source": [
        "correct_answers = {\"simple_4_gram\" : [], \"embedding_similarity\" : [], \"ensemble\" : []}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J26ogNimrWgH",
        "outputId": "719fb86a-f2c1-42f3-e19d-099643d94dae"
      },
      "source": [
        "# Simple-4-gram score\n",
        "additional_args = {\"n_gram_model\" : lm, \"pre_emb_model\" : fasttext_model300, \"ensemble\" : False}\n",
        "SCC = scc_reader(questions, answers, stop=True)\n",
        "SCC.predict_and_score(method=\"simple_4_gram\", additional_args=additional_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3576923076923077"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qc0Ke__c8QXC",
        "outputId": "f9a41b2e-0c50-4189-d723-d437a3c29fe0"
      },
      "source": [
        "# Embedding similarity score\n",
        "SCC = scc_reader(questions, answers, stop=True)\n",
        "SCC.predict_and_score(method=\"embedding_similarity\", additional_args=additional_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['_____']\n",
            "['_____']\n",
            "['_____']\n",
            "['_____']\n",
            "['_____']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43173076923076925"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNTZZdVhyhIr",
        "outputId": "78d8784c-7fe9-45de-f4eb-e9bcb0bf73d4"
      },
      "source": [
        "# Ensemble score\n",
        "additional_args[\"ensemble\"] = True\n",
        "SCC = scc_reader(questions, answers, stop=True)\n",
        "SCC.predict_and_score(method=\"ensemble\", additional_args=additional_args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['_____']\n",
            "['_____']\n",
            "['_____']\n",
            "['_____']\n",
            "['_____']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4394230769230769"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-qNa9AqPPVe"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq9BOAqeVEIV"
      },
      "source": [
        "import warnings  \n",
        "warnings.filterwarnings(action='ignore') #,category=DeprecationWarning,module='gensim')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cob0bwu4OYZj"
      },
      "source": [
        "#read in the answer file\n",
        "holding_list = []\n",
        "with open(\"lab2resources/sentence-completion/test_answer.csv\") as instream:\n",
        "    csvreader=csv.reader(instream)\n",
        "    alines=list(csvreader)\n",
        "    holding_list.append(alines)\n",
        "answers = [holding_list[0][i][1] for i, _ in enumerate(holding_list[0]) if i != 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gJlxRGR86C8"
      },
      "source": [
        "# All correct.\n",
        "correct = []\n",
        "# All incorrect.\n",
        "incorrect = []\n",
        "# N-gram incorrect\n",
        "n_g_incorrect = []\n",
        "# n-g over emb.\n",
        "n_g_vs_emb = []\n",
        "# emb over n-g.\n",
        "emb_vs_n_g = []\n",
        "# ensemble got right when other two didnt.\n",
        "ensemble_solved = []\n",
        "# Ensemble favouring n-gram.\n",
        "n_g_favour = []\n",
        "# Ensemble favouring word embeddings.\n",
        "emb_favour = []\n",
        "# Ensemble only.\n",
        "ensemble_only = []\n",
        "\n",
        "for i, (n_g, emb, ensemble) in enumerate(zip(correct_answers[\"simple_4_gram\"], correct_answers[\"embedding_similarity\"], correct_answers[\"ensemble\"])):\n",
        "  if n_g == emb == ensemble == 1:\n",
        "    correct.append(i)\n",
        "  if n_g == emb == ensemble == 0:\n",
        "    incorrect.append(i)\n",
        "  if n_g == 1 and emb == 0:\n",
        "    n_g_vs_emb.append(i)\n",
        "  if n_g == 0 and emb == 1:\n",
        "    emb_vs_n_g.append(i)\n",
        "  if n_g == emb == 0 and ensemble == 1:\n",
        "    ensemble_solved.append(i)\n",
        "  if n_g == 0:\n",
        "    n_g_incorrect.append(i)\n",
        "\n",
        "  if n_g == 0 and ensemble == 1 == emb:\n",
        "    emb_favour.append(i)\n",
        "  if emb == 0 and ensemble == 1 == n_g:\n",
        "    n_g_favour.append(i)\n",
        "\n",
        "  if ensemble == 1:\n",
        "    ensemble_only.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIRiUtFiPsDu"
      },
      "source": [
        "def error_analysis(index):\n",
        "  \"\"\"\n",
        "  Function to print out the answers predicted by each model stated, as well as the question (tokenized and not) and the correct answer.\n",
        "  \"\"\"\n",
        "\n",
        "  q = question([SCC.get_field(\"id\")[index], SCC.get_field(\"question\")[index], SCC.get_field(\"a)\")[index], SCC.get_field(\"b)\")[index],SCC.get_field(\"c)\")[index], SCC.get_field(\"d)\")[index], SCC.get_field(\"e)\")[index]])\n",
        "  answer = answers[index]\n",
        "  \n",
        "  additional_args = {\"n_gram_model\" : lm, \"pre_emb_model\" : fasttext_model300, \"ensemble\" : False}\n",
        "  pred_ngram = q.predict(\"simple_4_gram\", additional_args=additional_args)\n",
        "  answer_ngram = SCC.get_field(\"{})\".format(pred_ngram))[index]\n",
        "  \n",
        "  pred_emb = q.predict(\"embedding_similarity\", additional_args=additional_args)\n",
        "  answer_emb = SCC.get_field(\"{})\".format(pred_emb))[index]\n",
        "  \n",
        "  additional_args[\"ensemble\"] = True\n",
        "  pred_ensemble = q.predict(\"ensemble\", additional_args=additional_args)\n",
        "  answer_ensemble = SCC.get_field(\"{})\".format(pred_ensemble))[index]\n",
        "\n",
        "  answer_correct = SCC.get_field(\"{})\".format(answers[index]))[index]\n",
        "\n",
        "  # print()\n",
        "  print(\"------------------------------\")\n",
        "  print(SCC.get_field(\"question\")[index])\n",
        "  print(q.tokenized)\n",
        "  print()\n",
        "  print(answer_correct)\n",
        "  print()\n",
        "  print(\"N-gram: {}\".format(answer_ngram))\n",
        "  print(\"Embedd: {}\".format(answer_emb))\n",
        "  print(\"Ensemb: {}\".format(answer_ensemble))\n",
        "  print(\"------------------------------\")\n",
        "  print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIBUk_9Mp8LF"
      },
      "source": [
        "[error_analysis(index) for index in ensemble_solved]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ox8fLXA3UYIP"
      },
      "source": [
        "# Development + graphing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ielaJktPWB3"
      },
      "source": [
        "# Example development code for experimenting with the known parameter.\n",
        "lm_known = {}\n",
        "MAX_FILES=100\n",
        "\n",
        "training_shuffled = shuffle(training)\n",
        "training_shuffled = training_shuffled[:MAX_FILES]\n",
        "\n",
        "num = 0.2\n",
        "train, test = train_test_split(training_shuffled,test_size=num)\n",
        "\n",
        "for known in [5, 10, 25, 50]:\n",
        "\n",
        "\n",
        "  construct_params = {\n",
        "      \"known\" : known,\n",
        "      \"verbose\" : False,\n",
        "      \"remove_stopwords\" : True\n",
        "  }\n",
        "\n",
        "  # Initialize n-gram language model.\n",
        "  lm=n_gram_language_model(trainingdir=trainingdir,files=train, test_files=test, construct_params=construct_params)\n",
        "\n",
        "  lm_known[known] = lm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIhhkFu87y5N"
      },
      "source": [
        "knowns_test = [lm.compute_perplexity(filenames=lm.test_files,methodparams={\"method\":method}) for lm in lm_stop.values() for method in [\"unigram\", \"bigram\", \"trigram\", \"quad_gram\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_bYeH16-_uq"
      },
      "source": [
        "def chunker(lst, n):\n",
        "    \"\"\"\n",
        "    Chunnk lst (list) into n chunks.\n",
        "    \"\"\"\n",
        "    for i in range(0, len(lst), n):\n",
        "        yield lst[i:i + n]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpPnTACVTDeo"
      },
      "source": [
        "vocab_size = [len(lm.unigram) for lm in lm_stop.values()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zHEyast_wVk"
      },
      "source": [
        "one = []\n",
        "two = []\n",
        "three = []\n",
        "four = []\n",
        "for i_l in list(chunker(knowns_test,4)):\n",
        "  one.append(i_l[0])\n",
        "  two.append(i_l[1])\n",
        "  three.append(i_l[2])\n",
        "  four.append(i_l[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mzbaBfOJIi-"
      },
      "source": [
        "data_preproc = pd.DataFrame({\n",
        "    'Training Doc Size': [key for key, lm in lm_stop.items()], \n",
        "    'unigram': one,\n",
        "    'bigram': two,\n",
        "    \"trigram\":three,\n",
        "    '4-gram': four,\n",
        "    'vocab': vocab_size,\n",
        "    })\n",
        "\n",
        "data_preproc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Fonr3b4lKS5B",
        "outputId": "7e53fa18-d42b-4984-8b7b-07d2c3dc10d5"
      },
      "source": [
        "# Graphing function.\n",
        "ax = sns.lineplot(x='knowns', y='value', hue='variable', \n",
        "             data=pd.melt(data_preproc, ['knowns']))\n",
        "\n",
        "ax.set(xlabel=\"Known Parameter Value\", ylabel=\"Perplexity\")\n",
        "# ax._legend.set_title(\"N-Gram\")\n",
        "leg = ax.legend()\n",
        "leg.set_title(\"N-Gram\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3Eht3gWzIxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "ad1f0771-2f98-4e6f-ffbe-3d2bb237e32f"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "keys = [p[0] for p in gg]\n",
        "val = [p[1] for p in gg]\n",
        "\n",
        "ax = sns.barplot(y=keys, x=val, orient=\"horizontal\")\n",
        "ax.set(xlabel=\"Frequency\", ylabel=\"Word Token\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0.5, 'Word Token'), Text(0.5, 0, 'Frequency')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}